{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "841c2539-e2d8-4caf-9a35-ca80cc6d8f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, classification_report\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "import os\n",
    "import tldextract\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d581151-1f97-4d6a-a1ad-498909564969",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"malicious_phish.csv\")\n",
    "df = pd.DataFrame(data)\n",
    "label_mapping = {\n",
    "    'benign': 0,\n",
    "    'phishing': 1,\n",
    "    'defacement': 1,\n",
    "    'malware': 1\n",
    "}\n",
    "\n",
    "df['target'] = df['type'].map(label_mapping)\n",
    "\n",
    "if df['target'].isnull().sum() > 0:\n",
    "    print(\"\\nWarning: Ada label yang tidak dikenali, menghapus baris tersebut...\")\n",
    "    df = df.dropna(subset=['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c22e5c7-64e9-455b-a002-813f18bf5798",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3506864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_file = 'extracted_features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633186c5-1f25-4966-ae9c-5847b98e29c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(url):\n",
    "    features = {}\n",
    "\n",
    "    # Konversi ke string jaga-jaga kalau ada data bukan string\n",
    "    url = str(url)\n",
    "\n",
    "    # A. Fitur Panjang\n",
    "    features['url_length'] = len(url)\n",
    "    features['hostname_length'] = len(urlparse(url).netloc)\n",
    "    features['path_length'] = len(urlparse(url).path)\n",
    "\n",
    "    # B. Fitur Karakter Spesial\n",
    "    features['count_dot'] = url.count('.')\n",
    "    features['count_hyphen'] = url.count('-')\n",
    "    features['count_at'] = url.count('@')\n",
    "    features['count_question'] = url.count('?')\n",
    "    features['count_percent'] = url.count('%')\n",
    "    features['count_www'] = url.count('www')\n",
    "\n",
    "    # C. Fitur Pola \n",
    "    features['count_digits'] = sum(c.isdigit() for c in url)\n",
    "    features['count_letters'] = sum(c.isalpha() for c in url)\n",
    "\n",
    "    return pd.Series(features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06340ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cache ditemuakn: 'extracted_features.csv'.\n",
      "Shape Data:  (651191, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_length</th>\n",
       "      <th>hostname_length</th>\n",
       "      <th>path_length</th>\n",
       "      <th>count_dot</th>\n",
       "      <th>count_hyphen</th>\n",
       "      <th>count_at</th>\n",
       "      <th>count_question</th>\n",
       "      <th>count_percent</th>\n",
       "      <th>count_www</th>\n",
       "      <th>count_digits</th>\n",
       "      <th>count_letters</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>235</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_length  hostname_length  path_length  count_dot  count_hyphen  \\\n",
       "0          16                0           16          2             1   \n",
       "1          35                0           35          2             0   \n",
       "2          31                0           31          2             0   \n",
       "3          88               21           10          3             1   \n",
       "4         235               23           10          2             1   \n",
       "\n",
       "   count_at  count_question  count_percent  count_www  count_digits  \\\n",
       "0         0               0              0          0             0   \n",
       "1         0               0              0          0             1   \n",
       "2         0               0              0          0             1   \n",
       "3         0               1              0          1             7   \n",
       "4         0               1              0          0            22   \n",
       "\n",
       "   count_letters  target  \n",
       "0             13       1  \n",
       "1             29       0  \n",
       "2             25       0  \n",
       "3             63       1  \n",
       "4            199       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists(cache_file):\n",
    "    print(f\"File cache ditemuakn: '{cache_file}'.\")\n",
    "    final_df = pd.read_csv(cache_file)\n",
    "else:\n",
    "    print('cache file tidak ditemukan. Ekstraksi...')\n",
    "    feature_df = df['url'].apply(get_features)\n",
    "\n",
    "    final_df = pd.concat([feature_df, df['target']], axis=1)\n",
    "\n",
    "    final_df.to_csv(cache_file, index=False)\n",
    "    print(f\"Ekstraksi Selesai!, data disimpan ke '{cache_file}'\")\n",
    "\n",
    "print(\"Shape Data: \", final_df.shape )\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f5102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    428103\n",
      "1    223088\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(final_df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4492c310-e36a-438b-ae01-24e5503ab257",
   "metadata": {},
   "source": [
    "Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d5d9614-90a7-4940-b599-eb262aebefef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitur, pake drop untuk ngehapus kolom target.\n",
    "X = final_df.drop('target', axis=1)\n",
    "\n",
    "# target dismpan di y, outputnya 0 atau 1\n",
    "y = final_df['target']\n",
    "\n",
    "# bagian train data, pake function train_test_split(), test_size=0.2 itu agar dibagi 80% untuk train dan 20% untuk test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf3ca60",
   "metadata": {},
   "source": [
    "Inisiasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95bd5bc6-7aa8-4e10-8b74-b2dd69095c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CodeLocal\\python\\phishing\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "models[\"rf\"] = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "models['xgb'] = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656de42a",
   "metadata": {},
   "source": [
    "TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "533d5547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Ditemukan!: 'model_phishing.pkl'. \n",
      "Load model... \n",
      "[09:38:43] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "model_filename = \"model_phishing.pkl\" # xgboost tanpa tfidf\n",
    "\n",
    "final_model = None # xgboost model tanpa tfidf\n",
    "\n",
    "if os.path.exists(model_filename):\n",
    "    print(f\"Model Ditemukan!: '{model_filename}'. \\nLoad model... \")\n",
    "    final_model = joblib.load(model_filename)\n",
    "else:\n",
    "    print(\"model belum ada. Memulai proses training...\")\n",
    "    for name, model in models.items():\n",
    "        start_time = time.time()\n",
    "        print(f\"Training model: {name} ... \")\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        print(f\"   Akurasi: {acc*100:.2f}%\")\n",
    "        print(f\"   Waktu Training: {elapsed:.4f} detik\")\n",
    "        print(\"   Laporan Klasifikasi:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        print(f\"   Deteksi Benar (Phishing tertangkap): {tp}\")\n",
    "        print(f\"   Salah Prediksi (Phishing lolos/False Negative): {fn}  <-- INI YANG BAHAYA\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        final_model = model\n",
    "\n",
    "    joblib.dump(final_model, model_filename)\n",
    "    print(f\"Training Selesai! Model disimpan sebagai '{model_filename}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4593db4f",
   "metadata": {},
   "source": [
    "Optimasi Model XGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d26fc",
   "metadata": {},
   "source": [
    "TF-IDF Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4e4b549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file tfidf sudah ada!. Melakukan Load File...\n",
      "load file selesai.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         0\n",
       "2         0\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "651186    1\n",
       "651187    1\n",
       "651188    1\n",
       "651189    1\n",
       "651190    1\n",
       "Name: target, Length: 651191, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "numeric_features = pd.read_csv(cache_file)\n",
    "numeric_without_target = numeric_features.drop('target', axis=1)\n",
    "\n",
    "filename_tfidf = \"tfidf_vectorizer.pkl\" \n",
    "\n",
    "if os.path.exists(filename_tfidf):\n",
    "    print(f\"file tfidf sudah ada!. Melakukan Load File...\")\n",
    "    tfidf = joblib.load(filename_tfidf)\n",
    "    text_features = tfidf.transform(df['url'])\n",
    "    print('load file selesai.')\n",
    "else:\n",
    "    tfidf = TfidfVectorizer(analyzer='char', ngram_range=(3, 5), max_features=5000)\n",
    "    text_features = tfidf.fit_transform(df['url'])\n",
    "\n",
    "    text_features.shape\n",
    "    joblib.dump(tfidf, filename_tfidf)\n",
    "\n",
    "X_final = hstack([numeric_without_target.astype(float), text_features]) # untuk training pada xgboost yang baru\n",
    "y_final = df['target'] # target untuk xgboost yang baru\n",
    "\n",
    "y_final \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c6da48",
   "metadata": {},
   "source": [
    "Split Data Baru (Untuk Optimasi XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f4895f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_final, y_final, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88d396f",
   "metadata": {},
   "source": [
    "Model XGBoost baru (Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df5f184d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model belum ada, melakukan training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CodeLocal\\python\\phishing\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "d:\\CodeLocal\\python\\phishing\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.65477\n",
      "[1]\tvalidation_0-logloss:0.62001\n",
      "[2]\tvalidation_0-logloss:0.58804\n",
      "[3]\tvalidation_0-logloss:0.55893\n",
      "[4]\tvalidation_0-logloss:0.53223\n",
      "[5]\tvalidation_0-logloss:0.50732\n",
      "[6]\tvalidation_0-logloss:0.48458\n",
      "[7]\tvalidation_0-logloss:0.46340\n",
      "[8]\tvalidation_0-logloss:0.44379\n",
      "[9]\tvalidation_0-logloss:0.42554\n",
      "[10]\tvalidation_0-logloss:0.40883\n",
      "[11]\tvalidation_0-logloss:0.39300\n",
      "[12]\tvalidation_0-logloss:0.37829\n",
      "[13]\tvalidation_0-logloss:0.36452\n",
      "[14]\tvalidation_0-logloss:0.35159\n",
      "[15]\tvalidation_0-logloss:0.33942\n",
      "[16]\tvalidation_0-logloss:0.32826\n",
      "[17]\tvalidation_0-logloss:0.31767\n",
      "[18]\tvalidation_0-logloss:0.30770\n",
      "[19]\tvalidation_0-logloss:0.29845\n",
      "[20]\tvalidation_0-logloss:0.28967\n",
      "[21]\tvalidation_0-logloss:0.28127\n",
      "[22]\tvalidation_0-logloss:0.27348\n",
      "[23]\tvalidation_0-logloss:0.26617\n",
      "[24]\tvalidation_0-logloss:0.25912\n",
      "[25]\tvalidation_0-logloss:0.25266\n",
      "[26]\tvalidation_0-logloss:0.24638\n",
      "[27]\tvalidation_0-logloss:0.24048\n",
      "[28]\tvalidation_0-logloss:0.23482\n",
      "[29]\tvalidation_0-logloss:0.22970\n",
      "[30]\tvalidation_0-logloss:0.22488\n",
      "[31]\tvalidation_0-logloss:0.22024\n",
      "[32]\tvalidation_0-logloss:0.21591\n",
      "[33]\tvalidation_0-logloss:0.21153\n",
      "[34]\tvalidation_0-logloss:0.20773\n",
      "[35]\tvalidation_0-logloss:0.20378\n",
      "[36]\tvalidation_0-logloss:0.20041\n",
      "[37]\tvalidation_0-logloss:0.19685\n",
      "[38]\tvalidation_0-logloss:0.19381\n",
      "[39]\tvalidation_0-logloss:0.19049\n",
      "[40]\tvalidation_0-logloss:0.18770\n",
      "[41]\tvalidation_0-logloss:0.18450\n",
      "[42]\tvalidation_0-logloss:0.18206\n",
      "[43]\tvalidation_0-logloss:0.17916\n",
      "[44]\tvalidation_0-logloss:0.17648\n",
      "[45]\tvalidation_0-logloss:0.17420\n",
      "[46]\tvalidation_0-logloss:0.17171\n",
      "[47]\tvalidation_0-logloss:0.16979\n",
      "[48]\tvalidation_0-logloss:0.16744\n",
      "[49]\tvalidation_0-logloss:0.16538\n",
      "[50]\tvalidation_0-logloss:0.16363\n",
      "[51]\tvalidation_0-logloss:0.16168\n",
      "[52]\tvalidation_0-logloss:0.16020\n",
      "[53]\tvalidation_0-logloss:0.15844\n",
      "[54]\tvalidation_0-logloss:0.15688\n",
      "[55]\tvalidation_0-logloss:0.15542\n",
      "[56]\tvalidation_0-logloss:0.15401\n",
      "[57]\tvalidation_0-logloss:0.15263\n",
      "[58]\tvalidation_0-logloss:0.15140\n",
      "[59]\tvalidation_0-logloss:0.15022\n",
      "[60]\tvalidation_0-logloss:0.14883\n",
      "[61]\tvalidation_0-logloss:0.14768\n",
      "[62]\tvalidation_0-logloss:0.14648\n",
      "[63]\tvalidation_0-logloss:0.14533\n",
      "[64]\tvalidation_0-logloss:0.14449\n",
      "[65]\tvalidation_0-logloss:0.14340\n",
      "[66]\tvalidation_0-logloss:0.14234\n",
      "[67]\tvalidation_0-logloss:0.14153\n",
      "[68]\tvalidation_0-logloss:0.14092\n",
      "[69]\tvalidation_0-logloss:0.14034\n",
      "[70]\tvalidation_0-logloss:0.13942\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m      8\u001b[39m model_xgb_tuned = xgb.XGBClassifier(\n\u001b[32m      9\u001b[39m     n_estimators=\u001b[32m300\u001b[39m,        \n\u001b[32m     10\u001b[39m     tree_method=\u001b[33m'\u001b[39m\u001b[33mhist\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     n_jobs= -\u001b[32m1\u001b[39m              \n\u001b[32m     18\u001b[39m )\n\u001b[32m     19\u001b[39m start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[43mmodel_xgb_tuned\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_new\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     26\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSelesai dalam \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m detik\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m joblib.dump(model_xgb_tuned, filename_xgboost)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodeLocal\\python\\phishing\\venv\\Lib\\site-packages\\xgboost\\core.py:620\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    619\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodeLocal\\python\\phishing\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:1490\u001b[39m, in \u001b[36mXGBClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[39m\n\u001b[32m   1462\u001b[39m (\n\u001b[32m   1463\u001b[39m     model,\n\u001b[32m   1464\u001b[39m     metric,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1469\u001b[39m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[32m   1470\u001b[39m )\n\u001b[32m   1471\u001b[39m train_dmatrix, evals = _wrap_evaluation_matrices(\n\u001b[32m   1472\u001b[39m     missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1473\u001b[39m     X=X,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1487\u001b[39m     feature_types=\u001b[38;5;28mself\u001b[39m.feature_types,\n\u001b[32m   1488\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1490\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1493\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1495\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1497\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1498\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1499\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1500\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1501\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1502\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1504\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.objective):\n\u001b[32m   1505\u001b[39m     \u001b[38;5;28mself\u001b[39m.objective = params[\u001b[33m\"\u001b[39m\u001b[33mobjective\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodeLocal\\python\\phishing\\venv\\Lib\\site-packages\\xgboost\\core.py:620\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    619\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodeLocal\\python\\phishing\\venv\\Lib\\site-packages\\xgboost\\training.py:186\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    184\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    185\u001b[39m     bst.update(dtrain, i, obj)\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb_container\u001b[49m\u001b[43m.\u001b[49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    187\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    189\u001b[39m bst = cb_container.after_training(bst)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodeLocal\\python\\phishing\\venv\\Lib\\site-packages\\xgboost\\callback.py:240\u001b[39m, in \u001b[36mCallbackContainer.after_iteration\u001b[39m\u001b[34m(self, model, epoch, dtrain, evals)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, name \u001b[38;5;129;01min\u001b[39;00m evals:\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m name.find(\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m) == -\u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mDataset name should not contain `-`\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m score: \u001b[38;5;28mstr\u001b[39m = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_output_margin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m splited = score.split()[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# into datasets\u001b[39;00m\n\u001b[32m    242\u001b[39m \u001b[38;5;66;03m# split up `test-error:0.1234`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\CodeLocal\\python\\phishing\\venv\\Lib\\site-packages\\xgboost\\core.py:1989\u001b[39m, in \u001b[36mBooster.eval_set\u001b[39m\u001b[34m(self, evals, iteration, feval, output_margin)\u001b[39m\n\u001b[32m   1986\u001b[39m evnames = c_array(ctypes.c_char_p, [c_str(d[\u001b[32m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m evals])\n\u001b[32m   1987\u001b[39m msg = ctypes.c_char_p()\n\u001b[32m   1988\u001b[39m _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m1989\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterEvalOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1990\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1991\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1992\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdmats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1993\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1994\u001b[39m \u001b[43m        \u001b[49m\u001b[43mc_bst_ulong\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1995\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1996\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1997\u001b[39m )\n\u001b[32m   1998\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m msg.value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1999\u001b[39m res = msg.value.decode()  \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "filename_xgboost = r'models\\xgboost_phising_98acc.pkl' # xgboost baru\n",
    "\n",
    "if os.path.exists(filename_xgboost):\n",
    "    print(f\"Model sudah tersedia di {filename_xgboost}. Melakukan Load...\")\n",
    "    model_xgb_tuned = joblib.load(filename_xgboost)\n",
    "else:\n",
    "    print(\"Model belum ada, melakukan training\")\n",
    "    model_xgb_tuned = xgb.XGBClassifier(\n",
    "        n_estimators=300,        \n",
    "        tree_method='hist',\n",
    "        learning_rate=0.05,      \n",
    "        max_depth=6,            \n",
    "        scale_pos_weight=2,      \n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42,\n",
    "        n_jobs= -1              \n",
    "    )\n",
    "    start_time = time.time()\n",
    "    model_xgb_tuned.fit(\n",
    "        X_train_new,\n",
    "        y_train_new,\n",
    "        eval_set=[(X_test_new, y_test_new)],\n",
    "        early_stopping_rounds=30,\n",
    "        verbose=True\n",
    "    )\n",
    "    print(f\"Selesai dalam {time.time() - start_time:.2f} detik\")\n",
    "    joblib.dump(model_xgb_tuned, filename_xgboost)\n",
    "\n",
    "\n",
    "y_pred_new = model_xgb_tuned.predict(X_test_new)\n",
    "\n",
    "print(\"\\n=== HASIL SETELAH UPGRADE (NUMERIC + TEXT) ===\")\n",
    "print(classification_report(y_test_new, y_pred_new))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_new, y_pred_new).ravel()\n",
    "print(f\"False Negative (Bahaya) Sekarang: {fn}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b990d720",
   "metadata": {},
   "source": [
    "Model XGB Tuned V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da07fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_xgboost_V2 = r\"models\\xgboost_tuned_v2.pkl\"\n",
    "\n",
    "if os.path.exists(filename_xgboost_V2):\n",
    "    print(f\"Model sudah tersedia di {filename_xgboost_V2} \\nmelakukan Load... \")\n",
    "    model_xgb_tuned_V2 = joblib.load(filename_xgboost_V2)\n",
    "else:\n",
    "    print(\"Model belum ada, Melakukan training\")\n",
    "    model_xgb_tuned_V2 = xgb.XGBClassifier(\n",
    "        booster=\"gbtree\",\n",
    "        # Boosting strategy\n",
    "        n_estimators=600,\n",
    "        \n",
    "        learning_rate=0.05,\n",
    "\n",
    "\n",
    "\n",
    "        # Tree complexity (PALING PENTING)\n",
    "        max_depth=5,\n",
    "        min_child_weight=5,\n",
    "        gamma=0.1,\n",
    "\n",
    "        # Randomness & generalization (WAJIB utk TF-IDF)\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.6,\n",
    "\n",
    "        # Regularization (KRUSIAL utk text)\n",
    "        reg_alpha=0.5,\n",
    "        reg_lambda=1.0,\n",
    "\n",
    "        # Class imbalance (HITUNG, JANGAN TEBAK)\n",
    "        scale_pos_weight= 1.92,\n",
    "\n",
    "        # Performance\n",
    "        tree_method=\"hist\",\n",
    "        eval_metric=\"logloss\",\n",
    "\n",
    "        # Reproducibility & system\n",
    "        random_state=42,\n",
    "        n_jobs=1,   \n",
    "\n",
    "        \n",
    "    )\n",
    "    start_time = time.time()\n",
    "    model_xgb_tuned_V2.fit(\n",
    "        X_train_new, y_train_new,\n",
    "        eval_set=[(X_test_new, y_test_new)],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=True\n",
    "    )\n",
    "    print(f\"Selesai dalam {time.time() - start_time:.2f} detik\")\n",
    "    joblib.dump(model_xgb_tuned_V2, filename_xgboost_V2)\n",
    "\n",
    "y_pred_new_V2 = model_xgb_tuned_V2.predict(X_test_new)\n",
    "\n",
    "print(\"Hasil dari xgb tuned v2\")\n",
    "print(classification_report(y_test_new, y_pred_new_V2))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_new, y_pred_new_V2).ravel()\n",
    "print(f\"False Negative (Bahaya) Sekarang: {fn}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfcf480",
   "metadata": {},
   "source": [
    "Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb5b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_whitelist = pd.read_csv(r\"dataset\\top-1m.csv\", names=['no','domain'])\n",
    "set_whitelist = set(df_whitelist['domain'].astype(str).values)\n",
    "\n",
    "print(f\"berhasil memuat {len(set_whitelist)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a0aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_phishing(url_input):\n",
    "    \n",
    "    ext = tldextract.extract(url_input)\n",
    "    clean_domain = f\"{ext.domain}.{ext.suffix}\"\n",
    "  \n",
    "\n",
    "\n",
    "    if clean_domain in set_whitelist :\n",
    "        return print(\"Link Aman!\"), print(f\"clean domain: {clean_domain}\")\n",
    "    else:\n",
    "\n",
    "        features_num = get_features(url_input) # fitur untuk nomor\n",
    "        features_num_df = pd.DataFrame([features_num]) # biar jadi dataframe\n",
    "        features_text = tfidf.transform([url_input]) # fitur text\n",
    "        \n",
    "        X_predict = hstack([features_num_df.astype(float), features_text ]) \n",
    "\n",
    "        prediction = model_xgb_tuned_V2.predict(X_predict)[0]\n",
    "        probabilitas = model_xgb_tuned_V2.predict_proba(X_predict)[0][1]\n",
    "        percent = probabilitas * 100\n",
    "\n",
    "        if prediction == 1 :\n",
    "            return print(f\"Link tidak aman!, tingkat bahaya {percent:.2f}%\"), print(prediction), print(f\"clean domain: {clean_domain}\")\n",
    "        else :\n",
    "            return print(f\"Link aman!, tingkat bahaya hanya {percent:.2f}%\"), print(prediction), clean_domain\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cf44cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil = predict_phishing(\"https://www.youtube.com/watch?v=gPciUPwWJQQ\")\n",
    "hasil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb28b7c8",
   "metadata": {},
   "source": [
    "======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec5b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a925f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35903b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
