{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "841c2539-e2d8-4caf-9a35-ca80cc6d8f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, classification_report\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "import os\n",
    "import tldextract\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c571b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.3\n"
     ]
    }
   ],
   "source": [
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d581151-1f97-4d6a-a1ad-498909564969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah baris sebelum cleaning: 651191\n",
      "Jumlah baris setelah cleaning: 636316\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"malicious_phish.csv\")\n",
    "df = pd.DataFrame(data)\n",
    "label_mapping = {\n",
    "    'benign': 0,\n",
    "    'phishing': 1,\n",
    "    'defacement': 1,\n",
    "    'malware': 1\n",
    "}\n",
    "\n",
    "df['target'] = df['type'].map(label_mapping)\n",
    "\n",
    "if df['target'].isnull().sum() > 0:\n",
    "    print(\"\\nWarning: Ada label yang tidak dikenali, menghapus baris tersebut...\")\n",
    "    df = df.dropna(subset=['target'])\n",
    "\n",
    "# Cleaning Data\n",
    "\n",
    "print(f\"Jumlah baris sebelum cleaning: {len(df)}\")\n",
    "\n",
    "df['url'] = df['url'].str.replace(r'^htpps?://', '', regex=True)\n",
    "df['url'] = df['url'].str.replace(r'^http://', '', regex=True)\n",
    "\n",
    "\n",
    "df['url'] = df['url'].str.replace(r'^www\\.', '', regex=True )\n",
    "\n",
    "\n",
    "df = df.drop_duplicates(subset=['url'])\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Jumlah baris setelah cleaning: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a083a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>type</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>br-icloud.com.br</td>\n",
       "      <td>phishing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mp3raid.com/music/krizz_kaliko.html</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bopsecrets.org/rexroth/cr/1.htm</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>garage-pirenne.be/index.php?option=com_content...</td>\n",
       "      <td>defacement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adventure-nicaragua.net/index.php?option=com_m...</td>\n",
       "      <td>defacement</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636311</th>\n",
       "      <td>xbox360.ign.com/objects/850/850402.html</td>\n",
       "      <td>phishing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636312</th>\n",
       "      <td>games.teamxbox.com/xbox-360/1860/Dead-Space/</td>\n",
       "      <td>phishing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636313</th>\n",
       "      <td>gamespot.com/xbox360/action/deadspace/</td>\n",
       "      <td>phishing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636314</th>\n",
       "      <td>en.wikipedia.org/wiki/Dead_Space_(video_game)</td>\n",
       "      <td>phishing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636315</th>\n",
       "      <td>angelfire.com/goth/devilmaycrytonite/</td>\n",
       "      <td>phishing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>636316 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url        type  target\n",
       "0                                        br-icloud.com.br    phishing       1\n",
       "1                     mp3raid.com/music/krizz_kaliko.html      benign       0\n",
       "2                         bopsecrets.org/rexroth/cr/1.htm      benign       0\n",
       "3       garage-pirenne.be/index.php?option=com_content...  defacement       1\n",
       "4       adventure-nicaragua.net/index.php?option=com_m...  defacement       1\n",
       "...                                                   ...         ...     ...\n",
       "636311            xbox360.ign.com/objects/850/850402.html    phishing       1\n",
       "636312       games.teamxbox.com/xbox-360/1860/Dead-Space/    phishing       1\n",
       "636313             gamespot.com/xbox360/action/deadspace/    phishing       1\n",
       "636314      en.wikipedia.org/wiki/Dead_Space_(video_game)    phishing       1\n",
       "636315              angelfire.com/goth/devilmaycrytonite/    phishing       1\n",
       "\n",
       "[636316 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c22e5c7-64e9-455b-a002-813f18bf5798",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3506864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_file = 'extracted_features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "633186c5-1f25-4966-ae9c-5847b98e29c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(url):\n",
    "    features = {}\n",
    "\n",
    "    # Konversi ke string jaga-jaga kalau ada data bukan string\n",
    "    url = str(url)\n",
    "\n",
    "    if not url.startswith(('http://', 'https://')):\n",
    "        parse_url = \"http://\" + url\n",
    "    else:\n",
    "        parse_url = url\n",
    "    \n",
    "    try:\n",
    "        parsed = urlparse(parse_url)\n",
    "        hostname = parsed.netloc\n",
    "        path = parsed.path\n",
    "    except ValueError:\n",
    "        temp_url = parse_url.replace(\"http://\", \"\").replace(\"https://\", \"\")\n",
    "        \n",
    "        if \"/\" in temp_url:\n",
    "            parts = temp_url.split('/', 1)\n",
    "            hostname = parts[0]\n",
    "            path = \"/\" + parts[1]\n",
    "        else:\n",
    "            hostname = temp_url\n",
    "            path = \"\"\n",
    "\n",
    "    # A. Fitur Panjang\n",
    "    features['url_length'] = len(url)\n",
    "    features['hostname_length'] = len(hostname)\n",
    "    features['path_length'] = len(path)\n",
    "\n",
    "    # B. Fitur Karakter Spesial\n",
    "    features['count_dot'] = url.count('.')\n",
    "    features['count_hyphen'] = url.count('-')\n",
    "    features['count_at'] = url.count('@')\n",
    "    features['count_question'] = url.count('?')\n",
    "    features['count_percent'] = url.count('%')\n",
    "    features['count_www'] = url.count('www')\n",
    "\n",
    "    # C. Fitur Pola \n",
    "    features['count_digits'] = sum(c.isdigit() for c in url)\n",
    "    features['count_letters'] = sum(c.isalpha() for c in url)\n",
    "\n",
    "    return pd.Series(features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06340ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File cache ditemuakn: 'extracted_features.csv'.\n",
      "Shape Data:  (636316, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_length</th>\n",
       "      <th>hostname_length</th>\n",
       "      <th>path_length</th>\n",
       "      <th>count_dot</th>\n",
       "      <th>count_hyphen</th>\n",
       "      <th>count_at</th>\n",
       "      <th>count_question</th>\n",
       "      <th>count_percent</th>\n",
       "      <th>count_www</th>\n",
       "      <th>count_digits</th>\n",
       "      <th>count_letters</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_length  hostname_length  path_length  count_dot  count_hyphen  \\\n",
       "0          16               16            0          2             1   \n",
       "1          35               11           24          2             0   \n",
       "2          31               14           17          2             0   \n",
       "3          77               17           10          2             1   \n",
       "4         228               23           10          2             1   \n",
       "\n",
       "   count_at  count_question  count_percent  count_www  count_digits  \\\n",
       "0         0               0              0          0             0   \n",
       "1         0               0              0          0             1   \n",
       "2         0               0              0          0             1   \n",
       "3         0               1              0          0             7   \n",
       "4         0               1              0          0            22   \n",
       "\n",
       "   count_letters  target  \n",
       "0             13       1  \n",
       "1             29       0  \n",
       "2             25       0  \n",
       "3             56       1  \n",
       "4            195       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.exists(cache_file):\n",
    "    print(f\"File cache ditemuakn: '{cache_file}'.\")\n",
    "    df_feature = pd.read_csv(cache_file)\n",
    "else:\n",
    "    print('cache file tidak ditemukan. Ekstraksi...')\n",
    "    feature_df = df['url'].apply(get_features) \n",
    "\n",
    "    df_feature = pd.concat([feature_df, df['target']], axis=1)\n",
    "\n",
    "    df_feature.to_csv(cache_file, index=False)\n",
    "    print(f\"Ekstraksi Selesai!, data disimpan ke '{cache_file}'\")\n",
    "\n",
    "print(\"Shape Data: \", df_feature.shape )\n",
    "df_feature.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b46e300e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_length</th>\n",
       "      <th>hostname_length</th>\n",
       "      <th>path_length</th>\n",
       "      <th>count_dot</th>\n",
       "      <th>count_hyphen</th>\n",
       "      <th>count_at</th>\n",
       "      <th>count_question</th>\n",
       "      <th>count_percent</th>\n",
       "      <th>count_www</th>\n",
       "      <th>count_digits</th>\n",
       "      <th>count_letters</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636311</th>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636312</th>\n",
       "      <td>44</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636313</th>\n",
       "      <td>38</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636314</th>\n",
       "      <td>45</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636315</th>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>636316 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        url_length  hostname_length  path_length  count_dot  count_hyphen  \\\n",
       "0               16               16            0          2             1   \n",
       "1               35               11           24          2             0   \n",
       "2               31               14           17          2             0   \n",
       "3               77               17           10          2             1   \n",
       "4              228               23           10          2             1   \n",
       "...            ...              ...          ...        ...           ...   \n",
       "636311          39               15           24          3             0   \n",
       "636312          44               18           26          2             2   \n",
       "636313          38               12           26          1             0   \n",
       "636314          45               16           29          2             0   \n",
       "636315          37               13           24          1             0   \n",
       "\n",
       "        count_at  count_question  count_percent  count_www  count_digits  \\\n",
       "0              0               0              0          0             0   \n",
       "1              0               0              0          0             1   \n",
       "2              0               0              0          0             1   \n",
       "3              0               1              0          0             7   \n",
       "4              0               1              0          0            22   \n",
       "...          ...             ...            ...        ...           ...   \n",
       "636311         0               0              0          0            12   \n",
       "636312         0               0              0          0             7   \n",
       "636313         0               0              0          0             3   \n",
       "636314         0               0              0          0             0   \n",
       "636315         0               0              0          0             0   \n",
       "\n",
       "        count_letters  target  \n",
       "0                  13       1  \n",
       "1                  29       0  \n",
       "2                  25       0  \n",
       "3                  56       1  \n",
       "4                 195       1  \n",
       "...               ...     ...  \n",
       "636311             21       1  \n",
       "636312             29       1  \n",
       "636313             30       1  \n",
       "636314             36       1  \n",
       "636315             33       1  \n",
       "\n",
       "[636316 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0647634f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    423592\n",
      "1    212724\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_feature['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4492c310-e36a-438b-ae01-24e5503ab257",
   "metadata": {},
   "source": [
    "Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d5d9614-90a7-4940-b599-eb262aebefef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitur, pake drop untuk ngehapus kolom target.\n",
    "X = df_feature.drop('target', axis=1)\n",
    "\n",
    "# target dismpan di y, outputnya 0 atau 1\n",
    "y = df_feature['target']\n",
    "\n",
    "# bagian train data, pake function train_test_split(), test_size=0.2 itu agar dibagi 80% untuk train dan 20% untuk test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89bbd3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m aman = (\u001b[43my_train_new\u001b[49m == \u001b[32m0\u001b[39m).sum()\n\u001b[32m      2\u001b[39m bahaya = (y_train_new == \u001b[32m1\u001b[39m).sum()\n\u001b[32m      3\u001b[39m aman\n",
      "\u001b[31mNameError\u001b[39m: name 'y_train_new' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bf3ca60",
   "metadata": {},
   "source": [
    "Inisiasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95bd5bc6-7aa8-4e10-8b74-b2dd69095c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {}\n",
    "# models[\"rf\"] = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# models['xgb'] = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "model_xgb_tuned = xgb.XGBClassifier()\n",
    "model_xgb_tuned_V2 = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656de42a",
   "metadata": {},
   "source": [
    "TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "533d5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# model_filename = \"model_phishing.pkl\" # xgboost tanpa tfidf\n",
    "\n",
    "# final_model = None # xgboost model tanpa tfidf\n",
    "\n",
    "# if os.path.exists(model_filename):\n",
    "#     print(f\"Model Ditemukan!: '{model_filename}'. \\nLoad model... \")\n",
    "#     final_model = joblib.load(model_filename)\n",
    "# else:\n",
    "#     print(\"model belum ada. Memulai proses training...\")\n",
    "#     for name, model in models.items():\n",
    "#         start_time = time.time()\n",
    "#         print(f\"Training model: {name} ... \")\n",
    "\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         acc = accuracy_score(y_test, y_pred)\n",
    "#         elapsed = time.time() - start_time\n",
    "\n",
    "#         print(f\"   Akurasi: {acc*100:.2f}%\")\n",
    "#         print(f\"   Waktu Training: {elapsed:.4f} detik\")\n",
    "#         print(\"   Laporan Klasifikasi:\")\n",
    "#         print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        \n",
    "#         tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "#         print(f\"   Deteksi Benar (Phishing tertangkap): {tp}\")\n",
    "#         print(f\"   Salah Prediksi (Phishing lolos/False Negative): {fn}  <-- INI YANG BAHAYA\")\n",
    "#         print(\"-\" * 40)\n",
    "\n",
    "#         final_model = model\n",
    "\n",
    "#     joblib.dump(final_model, model_filename)\n",
    "#     print(f\"Training Selesai! Model disimpan sebagai '{model_filename}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4593db4f",
   "metadata": {},
   "source": [
    "Optimasi Model XGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d26fc",
   "metadata": {},
   "source": [
    "TF-IDF Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4e4b549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file tfidf sudah ada!. Melakukan Load File...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CodeLocal\\python\\phishing\\venv\\Lib\\site-packages\\sklearn\\base.py:463: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.6.1 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "d:\\CodeLocal\\python\\phishing\\venv\\Lib\\site-packages\\sklearn\\base.py:463: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.6.1 when using version 1.8.0. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load file selesai.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         0\n",
       "2         0\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "636311    1\n",
       "636312    1\n",
       "636313    1\n",
       "636314    1\n",
       "636315    1\n",
       "Name: target, Length: 636316, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "numeric_features = pd.read_csv(cache_file)\n",
    "numeric_without_target = numeric_features.drop('target', axis=1)\n",
    "\n",
    "filename_tfidf = \"tfidf_vectorizer.pkl\" \n",
    "\n",
    "if os.path.exists(filename_tfidf):\n",
    "    print(f\"file tfidf sudah ada!. Melakukan Load File...\")\n",
    "    tfidf = joblib.load(filename_tfidf)\n",
    "    text_features = tfidf.transform(df['url'])\n",
    "    print('load file selesai.')\n",
    "else:\n",
    "    tfidf = TfidfVectorizer(analyzer='char', ngram_range=(3, 5), max_features=5000)\n",
    "    text_features = tfidf.fit_transform(df['url'])\n",
    "\n",
    "    text_features.shape\n",
    "    joblib.dump(tfidf, filename_tfidf)\n",
    "\n",
    "X_final = hstack([numeric_without_target.astype(float), text_features]) # untuk training pada xgboost yang baru\n",
    "y_final = df['target'] # target untuk xgboost yang baru\n",
    "\n",
    "y_final \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c6da48",
   "metadata": {},
   "source": [
    "Split Data Baru (Untuk Optimasi XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f4895f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_final, y_final, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14a7a146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(339006)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "aman = (y_train_new == 0).sum()\n",
    "bahaya = (y_train_new == 1).sum()\n",
    "aman"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88d396f",
   "metadata": {},
   "source": [
    "Model XGBoost baru (Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df5f184d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model sudah tersedia di xgboost_phising_98acc.json. Melakukan Load...\n",
      "\n",
      "=== HASIL SETELAH UPGRADE (NUMERIC + TEXT) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94     84586\n",
      "           1       0.87      0.92      0.89     42678\n",
      "\n",
      "    accuracy                           0.92    127264\n",
      "   macro avg       0.91      0.92      0.92    127264\n",
      "weighted avg       0.93      0.92      0.92    127264\n",
      "\n",
      "False Negative (Bahaya) Sekarang: 3592\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filename_xgboost = r'xgboost_phising_98acc.json' # xgboost baru\n",
    "\n",
    "model_xgb_tuned = xgb.XGBClassifier(\n",
    "        n_estimators=1000,        \n",
    "        device='cuda',\n",
    "        learning_rate=0.05,      \n",
    "        max_depth=6,            \n",
    "        scale_pos_weight= aman / bahaya,      \n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42,\n",
    "        n_jobs= -1 ,\n",
    "        predictor=\"gpu_predictor\",   \n",
    "        tree_method='hist'         \n",
    "    )\n",
    "\n",
    "if os.path.exists(filename_xgboost):\n",
    "    print(f\"Model sudah tersedia di {filename_xgboost}. Melakukan Load...\")\n",
    "    model_xgb_tuned._estimator_type = \"classifier\"\n",
    "    model_xgb_tuned.load_model(filename_xgboost)\n",
    "    model_xgb_tuned.n_classes_ = 2\n",
    "\n",
    "else:\n",
    "    print(\"Model belum ada, melakukan training\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model_xgb_tuned.fit(\n",
    "        X_train_new,\n",
    "        y_train_new,\n",
    "        eval_set=[(X_test_new, y_test_new)],\n",
    "        early_stopping_rounds=30,\n",
    "        verbose=True\n",
    "    )\n",
    "    print(f\"Selesai dalam {time.time() - start_time:.2f} detik\")\n",
    "    model_xgb_tuned.save_model(filename_xgboost)\n",
    "\n",
    "\n",
    "y_pred_new = model_xgb_tuned.predict(X_test_new)\n",
    "\n",
    "print(\"\\n=== HASIL SETELAH UPGRADE (NUMERIC + TEXT) ===\")\n",
    "print(classification_report(y_test_new, y_pred_new))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_new, y_pred_new).ravel()\n",
    "print(f\"False Negative (Bahaya) Sekarang: {fn}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b990d720",
   "metadata": {},
   "source": [
    "Model XGB Tuned V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da07fb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model sudah tersedia di xgboost_tuned_v2.json \n",
      "melakukan Load... \n",
      "Hasil dari xgb tuned v2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96     84586\n",
      "           1       0.91      0.94      0.93     42678\n",
      "\n",
      "    accuracy                           0.95    127264\n",
      "   macro avg       0.94      0.95      0.94    127264\n",
      "weighted avg       0.95      0.95      0.95    127264\n",
      "\n",
      "False Negative (Bahaya) Sekarang: 2492\n"
     ]
    }
   ],
   "source": [
    "filename_xgboost_V2 = r\"xgboost_tuned_v2.json\"\n",
    "\n",
    "model_xgb_tuned_V2 = xgb.XGBClassifier(\n",
    "        booster=\"gbtree\",\n",
    "        n_estimators=10000,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        min_child_weight=5,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.6,\n",
    "        reg_alpha=0.5,\n",
    "        reg_lambda=1.0,\n",
    "        scale_pos_weight= aman / bahaya,\n",
    "        device='cuda',\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1,    \n",
    "        predictor=\"gpu_predictor\",  \n",
    "        tree_method='hist'\n",
    "        \n",
    "    )\n",
    "\n",
    "if os.path.exists(filename_xgboost_V2):\n",
    "    print(f\"Model sudah tersedia di {filename_xgboost_V2} \\nmelakukan Load... \")\n",
    "    model_xgb_tuned_V2._estimator_type = \"classifier\"\n",
    "    model_xgb_tuned_V2.load_model(filename_xgboost_V2)\n",
    "    model_xgb_tuned_V2.n_classes_ = 2\n",
    "\n",
    "else:\n",
    "    print(\"Model belum ada, Melakukan training\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model_xgb_tuned_V2.fit(\n",
    "        X_train_new, y_train_new,\n",
    "        eval_set=[(X_test_new, y_test_new)],\n",
    "        early_stopping_rounds=50,\n",
    "        verbose=True\n",
    "    )\n",
    "    print(f\"Selesai dalam {time.time() - start_time:.2f} detik\")\n",
    "    model_xgb_tuned_V2.save_model(filename_xgboost_V2)\n",
    "\n",
    "y_pred_new_V2 = model_xgb_tuned_V2.predict(X_test_new)\n",
    "\n",
    "print(\"Hasil dari xgb tuned v2\")\n",
    "print(classification_report(y_test_new, y_pred_new_V2))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_new, y_pred_new_V2).ravel()\n",
    "print(f\"False Negative (Bahaya) Sekarang: {fn}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfcf480",
   "metadata": {},
   "source": [
    "Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9eb5b199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "berhasil memuat 1000000\n"
     ]
    }
   ],
   "source": [
    "df_whitelist = pd.read_csv(r\"dataset\\top-1m.csv\", names=['no','domain'])\n",
    "set_whitelist = set(df_whitelist['domain'].astype(str).values)\n",
    "\n",
    "print(f\"berhasil memuat {len(set_whitelist)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a0aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_phishing(url_input):\n",
    "    \n",
    "#     ext = tldextract.extract(url_input)\n",
    "#     clean_domain = f\"{ext.domain}.{ext.suffix}\"\n",
    "  \n",
    "\n",
    "\n",
    "#     if clean_domain in set_whitelist :\n",
    "#         return print(\"Link Aman!\"), print(f\"clean domain: {clean_domain}\")\n",
    "#     else:\n",
    "\n",
    "#         features_num = get_features(url_input) # fitur untuk nomor\n",
    "#         features_num_df = pd.DataFrame([features_num]) # biar jadi dataframe\n",
    "#         features_text = tfidf.transform([url_input]) # fitur text\n",
    "        \n",
    "#         X_predict = hstack([features_num_df.astype(float), features_text ]) \n",
    "\n",
    "#         prediction = model_xgb_tuned_V2.predict(X_predict)[0]\n",
    "#         probabilitas = model_xgb_tuned_V2.predict_proba(X_predict)[0][1]\n",
    "#         percent = probabilitas * 100\n",
    "\n",
    "#         if prediction == 1 :\n",
    "#             return print(f\"Link tidak aman!, tingkat bahaya {percent:.2f}%\"), print(prediction), print(f\"clean domain: {clean_domain}\")\n",
    "#         else :\n",
    "#             return print(f\"Link aman!, tingkat bahaya hanya {percent:.2f}%\"), print(prediction), clean_domain\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb28b7c8",
   "metadata": {},
   "source": [
    "======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35903b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Link BERBAHAYA! (56.08%)', np.int64(1), 'ladanglima.com')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Fungsi cleaning yang sama dengan saat training\n",
    "def clean_url_text(url):\n",
    "    # Hapus http/https\n",
    "    url = re.sub(r'^https?://', '', url)\n",
    "    # Hapus www.\n",
    "    url = re.sub(r'^www\\.', '', url)\n",
    "    return url\n",
    "\n",
    "def predict_phishing(url_input):\n",
    "    # 1. Cek Whitelist dulu (Wajib untuk domain valid tapi tidak dikenal model)\n",
    "    ext = tldextract.extract(url_input)\n",
    "    clean_domain = f\"{ext.domain}.{ext.suffix}\"\n",
    "    \n",
    "    if clean_domain in set_whitelist:\n",
    "        return f\"Link Aman (Whitelisted)! Domain: {clean_domain}\", 0\n",
    "\n",
    "    # 2. Siapkan Fitur\n",
    "    # A. Fitur Numerik (Pakai URL ASLI/MENTAH karena butuh http untuk parsing)\n",
    "    features_num = get_features(url_input) \n",
    "    features_num_df = pd.DataFrame([features_num]) \n",
    "    \n",
    "    # B. Fitur Teks (WAJIB CLEANING DULU!)\n",
    "    # --- PERBAIKAN DI SINI ---\n",
    "    url_cleaned = clean_url_text(url_input) \n",
    "    features_text = tfidf.transform([url_cleaned]) \n",
    "    # -------------------------\n",
    "\n",
    "    # 3. Gabung & Prediksi\n",
    "    X_predict = hstack([features_num_df.astype(float), features_text])\n",
    "    \n",
    "    # Ambil probabilitas kelas 1 (Phishing)\n",
    "    probabilitas = model_xgb_tuned_V2.predict_proba(X_predict)[0][1]\n",
    "    prediction = model_xgb_tuned_V2.predict(X_predict)[0]\n",
    "    percent = probabilitas * 100\n",
    "\n",
    "    if prediction == 1:\n",
    "        return f\"Link BERBAHAYA! ({percent:.2f}%)\", prediction, clean_domain\n",
    "    else:\n",
    "        return f\"Link Aman. ({percent:.2f}%)\", prediction, clean_domain\n",
    "\n",
    "# Test ulang\n",
    "hasil = predict_phishing(\"https://ladanglima.com/distribution-faq/\")\n",
    "print(hasil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dc43b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
