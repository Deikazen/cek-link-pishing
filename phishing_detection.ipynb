{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841c2539-e2d8-4caf-9a35-ca80cc6d8f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix, classification_report\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ff4bc",
   "metadata": {},
   "source": [
    "command utk pertama kali run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c83aef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "berhasil memuat 1000000\n"
     ]
    }
   ],
   "source": [
    "# df_whitelist = pd.read_csv(r\"dataset\\top-1m.csv\", names=['no','domain'])\n",
    "# set_whitelist = set(df_whitelist['domain'].astype(str).values)\n",
    "\n",
    "# print(f\"berhasil memuat {len(set_whitelist)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d581151-1f97-4d6a-a1ad-498909564969",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"malicious_phish.csv\")\n",
    "df = pd.DataFrame(data)\n",
    "label_mapping = {\n",
    "    'benign': 0,\n",
    "    'phishing': 1,\n",
    "    'defacement': 1,\n",
    "    'malware': 1\n",
    "}\n",
    "\n",
    "df['target'] = df['type'].map(label_mapping)\n",
    "\n",
    "if df['target'].isnull().sum() > 0:\n",
    "    print(\"\\nWarning: Ada label yang tidak dikenali, menghapus baris tersebut...\")\n",
    "    df = df.dropna(subset=['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c22e5c7-64e9-455b-a002-813f18bf5798",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3506864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_file = 'extracted_features.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633186c5-1f25-4966-ae9c-5847b98e29c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(url):\n",
    "    features = {}\n",
    "\n",
    "    # Konversi ke string jaga-jaga kalau ada data bukan string\n",
    "    url = str(url)\n",
    "\n",
    "    # A. Fitur Panjang\n",
    "    features['url_length'] = len(url)\n",
    "    features['hostname_length'] = len(urlparse(url).netloc)\n",
    "    features['path_length'] = len(urlparse(url).path)\n",
    "\n",
    "    # B. Fitur Karakter Spesial\n",
    "    features['count_dot'] = url.count('.')\n",
    "    features['count_hyphen'] = url.count('-')\n",
    "    features['count_at'] = url.count('@')\n",
    "    features['count_question'] = url.count('?')\n",
    "    features['count_percent'] = url.count('%')\n",
    "    features['count_www'] = url.count('www')\n",
    "\n",
    "    # C. Fitur Pola \n",
    "    features['count_digits'] = sum(c.isdigit() for c in url)\n",
    "    features['count_letters'] = sum(c.isalpha() for c in url)\n",
    "\n",
    "    return pd.Series(features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06340ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(cache_file):\n",
    "    print(f\"File cache ditemuakn: '{cache_file}'.\")\n",
    "    final_df = pd.read_csv(cache_file)\n",
    "else:\n",
    "    print('cache file tidak ditemukan. Ekstraksi...')\n",
    "    feature_df = df['url'].apply(get_features)\n",
    "\n",
    "    final_df = pd.concat([feature_df, df['target']], axis=1)\n",
    "\n",
    "    final_df.to_csv(cache_file, index=False)\n",
    "    print(f\"Ekstraksi Selesai!, data disimpan ke '{cache_file}'\")\n",
    "\n",
    "print(\"Shape Data: \", final_df.shape )\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4492c310-e36a-438b-ae01-24e5503ab257",
   "metadata": {},
   "source": [
    "Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d9614-90a7-4940-b599-eb262aebefef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitur, pake drop untuk ngehapus kolom target.\n",
    "X = final_df.drop('target', axis=1)\n",
    "\n",
    "# target dismpan di y, outputnya 0 atau 1\n",
    "y = final_df['target']\n",
    "\n",
    "# bagian train data, pake function train_test_split(), test_size=0.2 itu agar dibagi 80% untuk train dan 20% untuk test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf3ca60",
   "metadata": {},
   "source": [
    "Inisiasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bd5bc6-7aa8-4e10-8b74-b2dd69095c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "models[\"rf\"] = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "models['xgb'] = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656de42a",
   "metadata": {},
   "source": [
    "TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model_filename = \"model_phishing.pkl\"\n",
    "\n",
    "final_model = None\n",
    "\n",
    "if os.path.exists(model_filename):\n",
    "    print(f\"Model Ditemukan!: '{model_filename}'. \\nLoad model... \")\n",
    "    final_model = joblib.load(model_filename)\n",
    "else:\n",
    "    print(\"model belum ada. Memulai proses training...\")\n",
    "    for name, model in models.items():\n",
    "        start_time = time.time()\n",
    "        print(f\"Training model: {name} ... \")\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        print(f\"   Akurasi: {acc*100:.2f}%\")\n",
    "        print(f\"   Waktu Training: {elapsed:.4f} detik\")\n",
    "        print(\"   Laporan Klasifikasi:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        print(f\"   Deteksi Benar (Phishing tertangkap): {tp}\")\n",
    "        print(f\"   Salah Prediksi (Phishing lolos/False Negative): {fn}  <-- INI YANG BAHAYA\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        final_model = model\n",
    "\n",
    "    joblib.dump(final_model, model_filename)\n",
    "    print(f\"Training Selesai! Model disimpan sebagai '{model_filename}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4593db4f",
   "metadata": {},
   "source": [
    "Optimasi Model XGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d26fc",
   "metadata": {},
   "source": [
    "TF-IDF Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e4b549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "numeric_features = pd.read_csv(cache_file)\n",
    "numeric_without_target = numeric_features.drop('target', axis=1)\n",
    "\n",
    "filename_tfidf = \"tfidf_vectorizer.pkl\"\n",
    "\n",
    "if os.path.exists(filename_tfidf):\n",
    "    print(f\"file tfidf sudah ada!. Melakukan Load File...\")\n",
    "    tfidf = joblib.load(filename_tfidf)\n",
    "    text_features = tfidf.transform(df['url'])\n",
    "    print('load file selesai.')\n",
    "else:\n",
    "    tfidf = TfidfVectorizer(analyzer='char', ngram_range=(3, 5), max_features=5000)\n",
    "    text_features = tfidf.fit_transform(df['url'])\n",
    "\n",
    "    text_features.shape\n",
    "    joblib.dump(tfidf, filename_tfidf)\n",
    "\n",
    "X_final = hstack([numeric_without_target.astype(float), text_features])\n",
    "y_final = df['target']\n",
    "\n",
    "y_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c6da48",
   "metadata": {},
   "source": [
    "Split Data Baru (Untuk Optimasi XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4895f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_final, y_final, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88d396f",
   "metadata": {},
   "source": [
    "Model XGBoost baru (Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename_xgboost = 'xgboost_phising_98acc.pkl'\n",
    "\n",
    "if os.path.exists(filename_xgboost):\n",
    "    print(f\"Model sudah tersedia di {filename_xgboost}. Melakukan Load...\")\n",
    "    model_xgb_tuned = joblib.load(filename_xgboost)\n",
    "else:\n",
    "    model_xgb_tuned = xgb.XGBClassifier(\n",
    "        n_estimators=500,        \n",
    "        learning_rate=0.05,      \n",
    "        max_depth=10,            \n",
    "        scale_pos_weight=2,      \n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False,\n",
    "        random_state=42,\n",
    "        n_jobs=-1                \n",
    "    )\n",
    "    start_time = time.time()\n",
    "    model_xgb_tuned.fit(X_train_new, y_train_new)\n",
    "    print(f\"Selesai dalam {time.time() - start_time:.2f} detik\")\n",
    "    joblib.dump(model_xgb_tuned, filename_xgboost)\n",
    "\n",
    "\n",
    "y_pred_new = model_xgb_tuned.predict(X_test_new)\n",
    "\n",
    "print(\"\\n=== HASIL SETELAH UPGRADE (NUMERIC + TEXT) ===\")\n",
    "print(classification_report(y_test_new, y_pred_new))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test_new, y_pred_new).ravel()\n",
    "print(f\"False Negative (Bahaya) Sekarang: {fn}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfcf480",
   "metadata": {},
   "source": [
    "Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f08a0aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_phishing(url_input):\n",
    "\n",
    "    features_num = get_features(url_input) # fitur untuk nomor\n",
    "    features_num_df = pd.DataFrame([features_num]) # biar jadi dataframe\n",
    "    features_text = tfidf.transform([url_input]) # fitur text\n",
    "\n",
    "    X_predict = hstack([features_num_df.astype(float), features_text ]) \n",
    "\n",
    "    prediction = model_xgb_tuned.predict(X_predict)[0]\n",
    "    probabilitas = model_xgb_tuned.predict_proba(X_predict)[0][1]\n",
    "\n",
    "\n",
    "    \n",
    "    return features_num, features_num_df, features_text, prediction, probabilitas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61cf44cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(url_length         80\n",
       " hostname_length     0\n",
       " path_length        80\n",
       " count_dot           4\n",
       " count_hyphen        0\n",
       " count_at            0\n",
       " count_question      0\n",
       " count_percent       0\n",
       " count_www           0\n",
       " count_digits       11\n",
       " count_letters      59\n",
       " dtype: int64,\n",
       "    url_length  hostname_length  path_length  count_dot  count_hyphen  \\\n",
       " 0          80                0           80          4             0   \n",
       " \n",
       "    count_at  count_question  count_percent  count_www  count_digits  \\\n",
       " 0         0               0              0          0            11   \n",
       " \n",
       "    count_letters  \n",
       " 0             59  ,\n",
       " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       " \twith 71 stored elements and shape (1, 5000)>,\n",
       " np.int64(0),\n",
       " np.float32(0.024274217))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasil = predict_phishing(\"groups.google.com/group/alt.conspiracy.jfk/browse_thread/thread/885ffad05b486021\")\n",
    "hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c10fa60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1179cc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
